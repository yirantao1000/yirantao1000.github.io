<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yiran Tao</title>
  
  <meta name="author" content="Yiran Tao">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<!-- <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>"> -->
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yiran Tao</name>
              </p>
              <p>Hi there! I am a senior undergraduate student at <a href="https://www.whu.edu.cn/">Wuhan University</a>, China, where I am fortunate to be advised by Prof. <a href="http://iip.whu.edu.cn/">Zhenzhong Chen</a> to work on computer vision research. I also spent half a year at <a href="https://www.harvard.edu/">Harvard University</a> as well as <a href="https://www.mit.edu/">MIT</a> as a visiting undergraduate student, and was fortunate to be advised by <a href="https://vcg.seas.harvard.edu/people/hanspeter-pfister">Hanspeter Pfister</a> to work on biomedical image analysis.              
              </p>
              
              <p style="text-align:center">
                <a href="mailto:yirantao1000@gmail.com">Email</a> &nbsp/&nbsp
                <a href="data/YiranTao_CV.pdf">CV</a> &nbsp/&nbsp
                <!-- <a href="data/JonBarron-bio.txt">Bio</a> &nbsp/&nbsp -->
                <!-- <a href="https://scholar.google.com/citations?hl=en&user=jktWnL8AAAAJ">Google Scholar</a> &nbsp/&nbsp -->
                <a href="https://www.linkedin.com/in/yiran-tao-7957a6188/">Linkedin</a> &nbsp/&nbsp
                <!-- <a href="https://github.com/jonbarron/">Github</a> -->
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/YiranTao.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/YiranTao.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am broadly interested in artificial intelligence, computer vision, and their applications to other academic fields.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>




        <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/VAD.jpeg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <!-- <a href="https://arxiv.org/abs/1503.00848" id="MCG_journal"> -->
              <!-- <a href="https://arxiv.org/abs/1503.00848"> -->
              <a>
                <papertitle>Memory-Guided Normality Patterns Representation Matching for Unsupervised Video Anomaly Detection</papertitle>
              </a>
              <br>
              <strong>Yiran Tao</strong>, Yaosi Hu, Zhenzhong Chen
              <br>
              In submission
              <br>            
              <p>We propose a straightfoward idea to address the task of UAD: to directly compare events in videos and detect anomalies based on events‚Äô similarities with others, and propose a novel model based on this idea.</p>              
            </td>
          </tr>
	
          
          
         
         <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/SPL.jpeg" alt="PontTuset" width="160" style="border-style: none"> 
            </td>
            <td width="75%" valign="middle">
              <!-- <a href="https://arxiv.org/abs/1503.00848" id="MCG_journal"> -->
              <a href="https://ieeexplore.ieee.org/document/9894684">           
                <papertitle>Temporal Weighting Appearance-Aligned Network for Nighttime Video Retrieval</papertitle>
              </a>
              <br>
              Weijian Ruan*, <strong>Yiran Tao*</strong>, Linjun Ruan, Xiujun Shu, Yu Qiao
              <br>
              <em>IEEE Signal Processing Letters</em>
              <br>            
              <p>We build dataset for a novel task, namely video-based person re-identification <em>during nighttime</em>, and propose a temporal weighting appearance-aligned model to tackle this task.</p>              
            </td>
          </tr> 
			
          
          

          <tr>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <img src="images/VCIP.jpeg" alt="PontTuset" width="160" style="border-style: none">
            </td>
            <td width="75%" valign="middle">
              <!-- <a href="https://arxiv.org/abs/1503.00848" id="MCG_journal"> -->
              <a href="https://ieeexplore.ieee.org/document/9675397/">
                <papertitle>Learn to Look Around: Deep Reinforcement Learning Agent for Video Saliency Prediction</papertitle>
              </a>
              <br>
              <strong>Yiran Tao</strong>, Yaosi Hu, Zhenzhong Chen
              <br>
              <em>IEEE International Conference on Visual Communications and Image Processing (VCIP)</em>, 2021
              <br>            
              <p>We propose a deep reinforcement learning agent that generates a window of frames containing the most highly correlated information for saliency prediction for each video frame, which assists backbone models to extract temporal information and promotes their performance.</p>
              
            </td>
          </tr>

          
					
					
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
                This website is modified from <a href="https://jonbarron.info/">Dr. Jon Barron</a>'s public source code. 
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
